{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e646ef",
   "metadata": {},
   "source": [
    "\n",
    "# Smoking & Drinking Risk — Teacher–Student (XGBoost) Pipeline\n",
    "**Generated:** 2025-10-16 13:07  \n",
    "\n",
    "Questo notebook implementa un flusso di **training con informazioni privilegiate** (Teacher–Student / Knowledge Distillation):  \n",
    "- **Teacher model:** allena un regressore utilizzando **tutte** le feature (incluse cliniche/laboratorio) per predire un **indice di rischio** costruito dai marker clinici.  \n",
    "- **Student model:** impara a **imitare** le predizioni del Teacher usando **solo feature semplici** (anagrafiche, antropometriche, pressione, vista/udito, fumo, alcol).  \n",
    "- **Produzione:** in filiale si usa **solo lo Student**, senza esami del sangue.\n",
    "\n",
    "Infine, si mappa l'`indice di rischio` ad un **premio assicurativo**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea2d69",
   "metadata": {},
   "source": [
    "## 1) Configurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Config ===\n",
    "DATA_PATH = \"train.csv\"   # <-- Modifica qui il nome del tuo file CSV se diverso\n",
    "SAVE_MODEL_DIR = \"models\"\n",
    "BASE_PREMIUM = 500.0      # premio base (€/anno)\n",
    "MAX_INCREASE = 0.8        # sovrapprezzo max = +80%\n",
    "\n",
    "import os\n",
    "os.makedirs(SAVE_MODEL_DIR, exist_ok=True)\n",
    "print(\"Config ok.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a308501",
   "metadata": {},
   "source": [
    "## 2) Import librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib only (no seaborn), 1 plot per figure as required\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# XGBoost (fallback to GradientBoosting if unavailable)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except Exception as e:\n",
    "    HAS_XGB = False\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "print(\"XGBoost available:\", HAS_XGB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c0daef",
   "metadata": {},
   "source": [
    "## 3) Caricamento dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f21e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcad7e45",
   "metadata": {},
   "source": [
    "## 4) Pulizia e mappature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ee820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copia per sicurezza\n",
    "df = df.copy()\n",
    "\n",
    "# Mappa categorie note\n",
    "if \"DRK_YN\" in df.columns:\n",
    "    df[\"DRK_YN\"] = df[\"DRK_YN\"].map({\"Y\":1, \"N\":0}).astype(\"Int64\")\n",
    "\n",
    "# Sex -> 0/1 se possibile\n",
    "if \"sex\" in df.columns:\n",
    "    # tentativo robusto\n",
    "    df[\"sex\"] = df[\"sex\"].astype(str).str.strip().str.lower()\n",
    "    map_sex = {\"male\":1, \"m\":1, \"1\":1, \"female\":0, \"f\":0, \"0\":0}\n",
    "    df[\"sex\"] = df[\"sex\"].map(lambda x: map_sex[x] if x in map_sex else np.nan)\n",
    "    df[\"sex\"] = df[\"sex\"].astype(\"Float64\")\n",
    "\n",
    "# SMK_stat_type_cd già 1/2/3\n",
    "if \"SMK_stat_type_cd\" in df.columns:\n",
    "    df[\"SMK_stat_type_cd\"] = pd.to_numeric(df[\"SMK_stat_type_cd\"], errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "# Crea BMI se height/weight\n",
    "if set([\"height\",\"weight\"]).issubset(df.columns):\n",
    "    h = pd.to_numeric(df[\"height\"], errors=\"coerce\")\n",
    "    w = pd.to_numeric(df[\"weight\"], errors=\"coerce\")\n",
    "    df[\"BMI\"] = w / ( (h/100.0)**2 )\n",
    "    df[\"BMI\"] = df[\"BMI\"].astype(\"Float64\")\n",
    "\n",
    "# Converte tutte le colonne numeriche possibili\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == \"object\":\n",
    "        try:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "print(\"Valori nulli per colonna (prime 30):\")\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c21f0",
   "metadata": {},
   "source": [
    "## 5) Definizione gruppi di feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36853462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature \"semplici\" (disponibili in filiale)\n",
    "simple_features = [\n",
    "    col for col in [\n",
    "        \"sex\",\"age\",\"height\",\"weight\",\"waistline\",\n",
    "        \"sight_left\",\"sight_right\",\"hear_left\",\"hear_right\",\n",
    "        \"SBP\",\"DBP\",\"SMK_stat_type_cd\",\"DRK_YN\",\"BMI\"\n",
    "    ] if col in df.columns\n",
    "]\n",
    "\n",
    "# Feature cliniche (laboratorio/urine/enzimi) — usate SOLO in training\n",
    "candidate_clinical = [\n",
    "    \"HDL_chole\",\"LDL_chole\",\"triglyceride\",\"hemoglobin\",\n",
    "    \"urine_protein\",\"serum_creatinine\",\"SGOT_AST\",\"SGOT_ALT\",\"gamma_GTP\"\n",
    "]\n",
    "clinical_features = [c for c in candidate_clinical if c in df.columns]\n",
    "\n",
    "print(\"Simple features:\", simple_features)\n",
    "print(\"Clinical features:\", clinical_features)\n",
    "\n",
    "# Rimuove righe con NaN nelle feature usate dal teacher (per semplicità)\n",
    "used_for_teacher = list(set(simple_features + clinical_features))\n",
    "df_clean = df.dropna(subset=used_for_teacher).reset_index(drop=True)\n",
    "print(\"Shape after dropna for teacher features:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85077e6f",
   "metadata": {},
   "source": [
    "## 6) Costruzione target 'health_risk' via PCA sulle feature cliniche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dba7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardizza le cliniche e applica PCA (1 componente)\n",
    "scaler = StandardScaler()\n",
    "X_clin = scaler.fit_transform(df_clean[clinical_features])\n",
    "\n",
    "pca = PCA(n_components=1, random_state=42)\n",
    "risk_raw = pca.fit_transform(X_clin).ravel()\n",
    "\n",
    "# Normalizza su [0,1]\n",
    "def minmax(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return (x - np.nanmin(x)) / (np.nanmax(x) - np.nanmin(x) + 1e-12)\n",
    "\n",
    "df_clean[\"health_risk\"] = minmax(risk_raw)\n",
    "\n",
    "print(\"Varianza spiegata dalla prima componente PCA:\", float(pca.explained_variance_ratio_[0]))\n",
    "df_clean[[\"health_risk\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd4958e",
   "metadata": {},
   "source": [
    "## 7) Split train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac0c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/Val/Test split sul teacher\n",
    "X_teacher = df_clean[simple_features + clinical_features].values\n",
    "y_teacher = df_clean[\"health_risk\"].values\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_teacher, y_teacher, test_size=0.2, random_state=42)\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_tr, y_tr, test_size=0.2, random_state=42)\n",
    "\n",
    "len_tr, len_va, len_te = len(y_tr), len(y_va), len(y_te)\n",
    "print(\"Train/Val/Test sizes:\", len_tr, len_va, len_te)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fbfef5",
   "metadata": {},
   "source": [
    "## 8) Training Teacher model (tutte le feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if HAS_XGB:\n",
    "    teacher = xgb.XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_alpha=0.0,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "else:\n",
    "    teacher = GradientBoostingRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "teacher.fit(X_tr, y_tr)\n",
    "\n",
    "pred_va = teacher.predict(X_va)\n",
    "pred_te = teacher.predict(X_te)\n",
    "\n",
    "def reg_report(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"RMSE\": mean_squared_error(y_true, y_pred, squared=False)\n",
    "    }\n",
    "\n",
    "print(\"Teacher Val:\", reg_report(y_va, pred_va))\n",
    "print(\"Teacher Test:\", reg_report(y_te, pred_te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba4315b",
   "metadata": {},
   "source": [
    "## 9) Training Student model (solo feature semplici) — distillazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label distillate dal teacher su TUTTO df_clean\n",
    "teacher_full_pred = teacher.predict(df_clean[simple_features + clinical_features].values)\n",
    "df_clean[\"teacher_pred\"] = teacher_full_pred\n",
    "\n",
    "# Split per lo Student usando SOLO simple features\n",
    "X_student_all = df_clean[simple_features].values\n",
    "y_student_all = df_clean[\"teacher_pred\"].values\n",
    "\n",
    "Xs_tr, Xs_te, ys_tr, ys_te = train_test_split(X_student_all, y_student_all, test_size=0.2, random_state=42)\n",
    "Xs_tr, Xs_va, ys_tr, ys_va = train_test_split(Xs_tr, ys_tr, test_size=0.2, random_state=42)\n",
    "\n",
    "if HAS_XGB:\n",
    "    student = xgb.XGBRegressor(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "else:\n",
    "    student = GradientBoostingRegressor(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "student.fit(Xs_tr, ys_tr)\n",
    "\n",
    "stu_va = student.predict(Xs_va)\n",
    "stu_te = student.predict(Xs_te)\n",
    "\n",
    "print(\"Student Val:\", reg_report(ys_va, stu_va))\n",
    "print(\"Student Test:\", reg_report(ys_te, stu_te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd62d1",
   "metadata": {},
   "source": [
    "## 10) Importanza feature (Student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb69194",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ottieni importanze (XGBoost o sklearn)\n",
    "if HAS_XGB:\n",
    "    importances = student.feature_importances_\n",
    "else:\n",
    "    importances = getattr(student, \"feature_importances_\", np.zeros(len(simple_features)))\n",
    "\n",
    "# Ordina e plottalo con matplotlib\n",
    "idx_sorted = np.argsort(importances)[::-1]\n",
    "features_sorted = [simple_features[i] for i in idx_sorted]\n",
    "importances_sorted = importances[idx_sorted]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(len(importances_sorted)), importances_sorted)\n",
    "plt.xticks(range(len(importances_sorted)), features_sorted, rotation=45, ha=\"right\")\n",
    "plt.title(\"Student Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8de22",
   "metadata": {},
   "source": [
    "## 11) Funzione di pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bea4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_premium(risk_index, base=BASE_PREMIUM, max_increase=MAX_INCREASE):\n",
    "    # risk_index può essere fuori [0,1] -> clamp\n",
    "    r = float(risk_index)\n",
    "    r = max(0.0, min(1.0, r))\n",
    "    return base * (1.0 + max_increase * r)\n",
    "\n",
    "# Esempio su test set dello Student\n",
    "risk_pred_test = student.predict(Xs_te)\n",
    "# normalizzazione opzionale su [0,1]\n",
    "risk_min, risk_max = np.min(risk_pred_test), np.max(risk_pred_test) + 1e-12\n",
    "risk_norm = (risk_pred_test - risk_min) / (risk_max - risk_min)\n",
    "\n",
    "premiums = [compute_premium(r) for r in risk_norm]\n",
    "print(\"Esempio premi (prime 10):\", premiums[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1113d",
   "metadata": {},
   "source": [
    "## 12) Helper: predizione per un singolo cliente (solo feature semplici)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cdbc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Attenzione: lo Student è addestrato su df_clean (dopo dropna). \n",
    "# Per un cliente nuovo, bisogna passare esattamente le simple_features in questo ordine.\n",
    "\n",
    "def predict_client_premium(client_dict):\n",
    "    # Crea vettore nello stesso ordine delle simple_features\n",
    "    x = []\n",
    "    for col in simple_features:\n",
    "        if col not in client_dict:\n",
    "            raise ValueError(f\"Manca la feature richiesta: {col}\")\n",
    "        x.append(client_dict[col])\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    # Predizione rischio dallo Student\n",
    "    risk_pred = student.predict(x)[0]\n",
    "    # Normalizzazione rispetto a train dello Student (usa le stesse statistiche del batch test come esempio)\n",
    "    r = (risk_pred - risk_min) / (risk_max - risk_min)\n",
    "    premium = compute_premium(r)\n",
    "    return float(r), float(premium)\n",
    "\n",
    "# Esempio di input (adatta ai tuoi dati reali)\n",
    "example_client = {k: df_clean.iloc[0][k] for k in simple_features}\n",
    "risk_idx, prem = predict_client_premium(example_client)\n",
    "print(\"Risk index (normalized):\", round(risk_idx, 3), \" -> Premium (€):\", round(prem, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2755414",
   "metadata": {},
   "source": [
    "## 13) Salvataggio modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4032b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(SAVE_MODEL_DIR, \"teacher_model.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(teacher, f)\n",
    "with open(os.path.join(SAVE_MODEL_DIR, \"student_model.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(student, f)\n",
    "\n",
    "meta = {\n",
    "    \"simple_features\": simple_features,\n",
    "    \"clinical_features\": clinical_features,\n",
    "    \"pca_variance_explained\": float(pca.explained_variance_ratio_[0]),\n",
    "    \"base_premium\": BASE_PREMIUM,\n",
    "    \"max_increase\": MAX_INCREASE,\n",
    "    \"has_xgboost\": bool(HAS_XGB)\n",
    "}\n",
    "with open(os.path.join(SAVE_MODEL_DIR, \"metadata.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(meta, f)\n",
    "\n",
    "print(\"Modelli salvati in:\", SAVE_MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780c42c",
   "metadata": {},
   "source": [
    "\n",
    "## Note e miglioramenti possibili\n",
    "- **Calibrazione premio:** valuta su dati storici sinistri/premi per tarare `BASE_PREMIUM` e `MAX_INCREASE`.\n",
    "- **Explainability:** si può aggiungere SHAP (se disponibile) per spiegare le decisioni dello Student.\n",
    "- **Validazione:** aggiungere K-Fold CV e metriche stabili per ridurre overfitting.\n",
    "- **Robustezza:** gestire outlier, winsorization, e trasformazioni robuste su variabili con code pesanti.\n",
    "- **Privacy:** i marker clinici sono usati solo in training (Teacher) e mai richiesti in filiale (Student).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
